{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nfrom matplotlib import pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading the data and storing it into a dictionary","metadata":{}},{"cell_type":"code","source":"root='/kaggle/input/resume-dataset/data/data/'\ndata={}\nfor i in os.listdir(root):\n    for j in os.walk(root+i):\n        for k in j[2]:\n            data[root+i+'/'+k]=i","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Converting data dictionary to pandas dataframe","metadata":{}},{"cell_type":"code","source":"data=pd.DataFrame(data.items(),columns=['file','type'])\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Distribution Visualization","metadata":{}},{"cell_type":"code","source":"count_=data['type'].value_counts()\ncount_.plot(kind='bar', color='r', alpha=.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading Data from PDF Files","metadata":{}},{"cell_type":"code","source":"! pip install tika\nfrom tika import parser ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts_cv=[]\nempty_cv=[]\nfor i in range(len(data)):\n    raw = parser.from_file(data.iloc[i]['file'])\n    try:\n        texts_cv.append(raw['content'].replace('\\n',' '))\n    except:\n        texts_cv.append('')\n        empty_cv.append(i)\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts_cv[0] # sample cv text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(empty_cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['text']=texts_cv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dropping Empty CV","metadata":{}},{"cell_type":"code","source":"data=data.drop(empty_cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA on CV Content","metadata":{}},{"cell_type":"code","source":"cv_length=[len(i) for i in texts_cv]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(cv_length)\nplt.xlabel('cv sentence length')\nplt.ylabel('occurrences')\nplt.title('CV length')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statistics\nmean = sum(cv_length) / len(cv_length) #mean\nstd = statistics.pstdev(cv_length) #Standard deviation\nmean,std","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Out of the range of (Mean +- 3*std) is considered outlier","metadata":{}},{"cell_type":"code","source":"vocab_size= int(mean+ (3*std))\nvocab_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Splitting","metadata":{}},{"cell_type":"code","source":"def split_data(data,ratio):\n    last=int(len(data)*ratio)\n    return data[:last], data[last:]\n\ndata=data.sample(frac=1)\ntrain,test=split_data(data,.8)\nvalidation,train=split_data(data,.08)\n# train:validation:test=70:10:20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making sure each subset has all the classes","metadata":{}},{"cell_type":"code","source":"print(len(train[\"type\"].value_counts()))\nprint(len(test[\"type\"].value_counts()))\nprint(len(validation[\"type\"].value_counts()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=train['text']\nX_test=test['text']\nX_validation=validation['text']\n\ny_train=train['type']\ny_test=test['type']\ny_validation=validation['type']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Traditional ML models on raw data","metadata":{}},{"cell_type":"markdown","source":"## First Try with TF-IDF vectorizer","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer #Term Frequency Inverse Document Frequency\nvectorizer = TfidfVectorizer(ngram_range=(1,5),max_features=vocab_size)\nX_train_tfidf = vectorizer.fit_transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_validation_tfidf=vectorizer.transform(X_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\ndef score_prediction(model,X_train,X_test,y_train,y_test):\n    model.fit(X_train,y_train)\n    pr = model.predict(X_test)\n    acc_score = metrics.accuracy_score(y_test,pr)\n    pre_score = metrics.precision_score(y_test,pr,average=\"weighted\")\n    recall= metrics.recall_score(y_test,pr,average=\"weighted\")\n    f1= metrics.f1_score(y_test,pr,average=\"weighted\")\n    mcc= metrics.matthews_corrcoef(y_test,pr)\n    return acc_score,pre_score,recall,f1,mcc\nacc_score = {}\npre_score = {}\nrecall_score={}\nf1_score={}\nmcc_score={}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier\n\n\nlg = LogisticRegression(penalty='l1',solver='liblinear')\nsv = SVC(kernel='sigmoid',gamma=1.0)\ndtc = DecisionTreeClassifier(max_depth=5)\nknn = KNeighborsClassifier()\nrfc = RandomForestClassifier(n_estimators=50,random_state=2)\netc = ExtraTreesClassifier(n_estimators=50,random_state=2)\nbg = BaggingClassifier(n_estimators=50,random_state=2)\ngbc = GradientBoostingClassifier(n_estimators=50,random_state=2)\n\n\nclfs= {\n    'LR':lg,\n    'SVM':sv,\n    'DTC':dtc,\n    'KNN':knn,\n    'RFC':rfc,\n    'ETC':etc,\n    'BG':bg,\n    'GBC':gbc,\n}\nfor name,clf in clfs.items():\n    acc_score[name],pre_score[name],recall_score[name],f1_score[name],mcc_score[name] = score_prediction(clf,X_train_tfidf,X_validation_tfidf,y_train,y_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Result Analysis","metadata":{}},{"cell_type":"code","source":"acc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mcc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lists = sorted(acc_score.items()) # sorted by key, return a list of tuples\n\nx, y = zip(*lists) # unpack a list of pairs into two tuples\n\nplt.bar( x, y)\nplt.xlabel('Model')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lists = sorted(mcc_score.items()) # sorted by key, return a list of tuples\n\nx, y = zip(*lists) # unpack a list of pairs into two tuples\n\nplt.bar( x, y)\nplt.xlabel('Model')\nplt.ylabel('MCC')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boosting is the best ml model for this problem","metadata":{}},{"cell_type":"markdown","source":"# Experiment with data cleaning","metadata":{}},{"cell_type":"markdown","source":"## Delete Stop words","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\n \nnltk.download('stopwords')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,5),max_features=vocab_size,stop_words=stopwords.words('english'))\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_validation_tfidf=vectorizer.transform(X_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Since Gradient Boosting had the heighest performance","metadata":{}},{"cell_type":"code","source":"score_prediction(gbc,X_train_tfidf,X_validation_tfidf,y_train,y_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deleting stop words upgraded the performance","metadata":{}},{"cell_type":"markdown","source":"# Keep Alphabetic Characters Only","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,5),max_features=vocab_size,stop_words=stopwords.words('english'),token_pattern=r'(?u)\\b[A-Za-z]+\\b')\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_validation_tfidf=vectorizer.transform(X_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_prediction(gbc,X_train_tfidf,X_validation_tfidf,y_train,y_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## This made the performance worse","metadata":{}},{"cell_type":"markdown","source":"# Bag-of-words","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer(ngram_range=(1,5),max_features=vocab_size,stop_words=stopwords.words('english'))\nX_train_bow = vectorizer.fit_transform(X_train)\nX_validation_bow=vectorizer.transform(X_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_prediction(gbc,X_train_bow,X_validation_bow,y_train,y_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF-IDF is slightly better than BoW","metadata":{}},{"cell_type":"markdown","source":"# Try Deep Learning","metadata":{}},{"cell_type":"markdown","source":"## We will continue with the best configeration that is TF-IDF with deleting stop words","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,5),max_features=vocab_size,stop_words=stopwords.words('english'))\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_validation_tfidf=vectorizer.transform(X_validation)\n\nX_train_tfidf_arr=X_train_tfidf.toarray()\ny_train_ohe= pd.get_dummies(y_train).values\n\nX_validation_tfidf_arr=X_validation_tfidf.toarray()\ny_validation_ohe= pd.get_dummies(y_validation).values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_sp=len(X_train_tfidf_arr[0])\nout_sp=len(y_validation_ohe[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multi-layer Perceptron","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import mnist\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense,LSTM\nfrom sklearn import metrics\nmodel = Sequential()\nmodel.add(Dense(2048,input_shape = (input_sp,), activation = 'relu'))\nmodel.add(Dense(1024, activation = 'relu'))\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(64, activation = 'relu'))\nmodel.add(Dense(out_sp,activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',metrics=['accuracy',])\nhistory= model.fit(X_train_tfidf_arr, y_train_ohe, epochs=50, batch_size=128,verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = list(range(len(history.history['accuracy'])))\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\n\n\nfig.set_size_inches(20,10)\n\nax[0].plot(epochs , train_acc , 'go-' ,color='r', label = 'Training Accuracy')\nax[0].set_title('Training Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\n\nax[1].plot(epochs , train_loss , 'g-o' ,color='r', label = 'Training Loss')\nax[1].set_title('Training Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Training Loss\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"proba=model.predict(X_validation_tfidf_arr)\npr = np.argmax(proba,axis=1)\ntrue=np.argmax(y_validation_ohe,axis=1)\n\nacc_score = metrics.accuracy_score(true,pr)\npre_score = metrics.precision_score(true,pr,average=\"weighted\")\nrecall= metrics.recall_score(true,pr,average=\"weighted\")\nf1= metrics.f1_score(true,pr,average=\"weighted\")\nmcc= metrics.matthews_corrcoef(true,pr)\nacc_score,pre_score,recall,f1,mcc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model overfitted. Adding Dropout","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Dropout\nmodel = Sequential()\nmodel.add(Dense(2048,input_shape = (input_sp,), activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1024, activation = 'relu'))\nmodel.add(Dropout(.4))\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dropout(.3))\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dropout(.2))\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(.1))\nmodel.add(Dense(64, activation = 'relu'))\nmodel.add(Dense(out_sp,activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',metrics=['accuracy',])\nhistory= model.fit(X_train_tfidf_arr, y_train_ohe, epochs=50, batch_size=128,verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"proba=model.predict(X_validation_tfidf_arr)\npr = np.argmax(proba,axis=1)\ntrue=np.argmax(y_validation_ohe,axis=1)\n\nacc_score = metrics.accuracy_score(true,pr)\npre_score = metrics.precision_score(true,pr,average=\"weighted\")\nrecall= metrics.recall_score(true,pr,average=\"weighted\")\nf1= metrics.f1_score(true,pr,average=\"weighted\")\nmcc= metrics.matthews_corrcoef(true,pr)\nacc_score,pre_score,recall,f1,mcc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP Didn't work","metadata":{}},{"cell_type":"markdown","source":"# Bi-LSTM","metadata":{}},{"cell_type":"code","source":"# Functional API\nfrom tensorflow.keras import models, layers, optimizers\ninput_ = layers.Input(shape =(input_sp,),name='input')\nx=layers.Reshape((input_sp, 1), input_shape = (input_sp, ))(input_)\nx = layers.Bidirectional(layers.LSTM(15,dropout=0.2, return_sequences=False),name='bidirectional-lstm')(x) \nx = layers.Dropout(0.2, name='dropout')(x)\nx = layers.Dense(64, activation='relu', name='dense')(x)\noutput = layers.Dense(out_sp,activation='softmax', name='classification')(x)\n\nmodel = models.Model(input_, output)\n\nopt = optimizers.Adam(learning_rate=0.01) # because bi-lstms are slow, cannot affort high epoch, therefore higher learning rate for faster convergence \nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history= model.fit(X_train_tfidf_arr, y_train_ohe, epochs=50, batch_size=128,verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"proba=model.predict(X_validation_tfidf_arr)\npr = np.argmax(proba,axis=1)\ntrue=np.argmax(y_validation_ohe,axis=1)\n\nacc_score = metrics.accuracy_score(true,pr)\npre_score = metrics.precision_score(true,pr,average=\"weighted\")\nrecall= metrics.recall_score(true,pr,average=\"weighted\")\nf1= metrics.f1_score(true,pr,average=\"weighted\")\nmcc= metrics.matthews_corrcoef(true,pr)\nacc_score,pre_score,recall,f1,mcc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformers","metadata":{}},{"cell_type":"code","source":"import transformers\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer\nmodel_name = \"distilbert-base-uncased\"\ntrain_dataset = Dataset.from_pandas(train)\nvalid_dataset = Dataset.from_pandas(validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(train['type'].unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install evaluate\nfrom transformers import DataCollatorWithPadding\nfrom transformers import TrainingArguments, Trainer\nimport evaluate\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_valid = valid_dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = list(set(train['type'].to_list()))\nlabel_count = len(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def categorize(x):\n  return {\"labels\": [labels.index(type_) for type_ in x['type']]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorized_train = tokenized_train.map(categorize, batched=True)\ncategorized_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorized_valid = tokenized_valid.map(categorize, batched=True)\ncategorized_valid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"/kaggle/working/\",\n    learning_rate=2e-4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    evaluation_strategy = \"epoch\",\n    logging_strategy=\"epoch\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=categorized_train,\n    eval_dataset=categorized_valid,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n    \n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test with freezing layers (if needed)","metadata":{}},{"cell_type":"code","source":"i=0\nfor name, param in model.named_parameters(): \n    i+=1\n    if(i>100):\n        break\n    param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = trainer.predict(categorized_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr = np.argmax(predictions.predictions, axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true=predictions.label_ids\nacc_score = metrics.accuracy_score(true,pr)\npre_score = metrics.precision_score(true,pr,average=\"weighted\")\nrecall= metrics.recall_score(true,pr,average=\"weighted\")\nf1= metrics.f1_score(true,pr,average=\"weighted\")\nmcc= metrics.matthews_corrcoef(true,pr)\nacc_score,pre_score,recall,f1,mcc","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model('cv-classifier')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Best Option is to use Gradient Boosting with TF-IDF vectorizer with stop-words removal","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,5),max_features=vocab_size,stop_words=stopwords.words('english'))\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_validation_tfidf = vectorizer.transform(X_validation)\nX_test_ifidf = vectorizer.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the datasets","metadata":{}},{"cell_type":"code","source":"train.to_csv('train.csv',index=False)\ntest.to_csv('test.csv',index=False)\nvalidation.to_csv('validation.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Evaluation of the best model on test dataset","metadata":{}},{"cell_type":"code","source":"gbc = GradientBoostingClassifier(n_estimators=50,random_state=2)\ngbc.fit(X_train_tfidf,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr = gbc.predict(X_test_ifidf)\nacc_score = metrics.accuracy_score(y_test,pr)\npre_score = metrics.precision_score(y_test,pr,average=\"weighted\")\nrecall= metrics.recall_score(y_test,pr,average=\"weighted\")\nf1= metrics.f1_score(y_test,pr,average=\"weighted\")\nmcc= metrics.matthews_corrcoef(y_test,pr)\nprint(\"accuracy: \" + str(acc_score)+\" precision: \"+ str(pre_score) + \" recall: \"+ str(recall)+ \" f1-score: \"+str(f1)+\" mcc: \"+str(mcc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the model","metadata":{}},{"cell_type":"code","source":"import pickle\npickle.dump(gbc, open('gradient_boosting.sav', 'wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### If needed, load the model this way:","metadata":{}},{"cell_type":"code","source":"filename='/kaggle/working/gradient_boosting.sav'\ngbc_load=pickle.load(open(filename, 'rb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Note that results might vary by a small margin due to the randomization involved","metadata":{}}]}